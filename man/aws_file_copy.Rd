% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/files.R
\name{aws_file_copy}
\alias{aws_file_copy}
\title{Copy files between buckets}
\usage{
aws_file_copy(remote_path, bucket, force = FALSE, ...)
}
\arguments{
\item{remote_path}{(character) one or more remote S3 paths. required}

\item{bucket}{(character) bucket to copy files to. required.
if the bucket does not exist we prompt you asking if you'd like
the bucket to be created}

\item{force}{(logical) force bucket creation without going through
the prompt. default: \code{FALSE}. Should only be set to \code{TRUE} when
required for non-interactive use.}

\item{...}{named parameters passed on to \code{\link[s3fs:copy]{s3fs::s3_file_copy()}}}
}
\value{
vector of paths, length matches \code{length(remote_path)}
}
\description{
Copy files between buckets
}
\examples{
\dontrun{
# create files in an existing bucket
tfiles <- replicate(n = 3, tempfile())
for (i in tfiles) cat("Hello\nWorld\n", file = i)
paths <- s3_path("s64-test-2", c("aaa", "bbb", "ccc"), ext = "txt")
aws_file_upload(tfiles, paths)

# create a new bucket
new_bucket <- aws_bucket_create(bucket = "s64-test-3")

# add existing files to the new bucket
aws_file_copy(paths, path_as_s3(new_bucket))
# create bucket that doesn't exist yet
aws_file_copy(paths, "s64-test-4")
}
}
